{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolo Nas Classifier\n",
    "## notebook complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Exploration:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from super_gradients import Trainer\n",
    "from super_gradients.training.metrics import DetectionMetrics_050\n",
    "from super_gradients.training.models.detection_models.pp_yolo_e import (\n",
    "    PPYoloEPostPredictionCallback\n",
    ")\n",
    "from super_gradients.training import Trainer, training_hyperparams\n",
    "from super_gradients.training.processing.processing import ComposeProcessing, NormalizeImage, Resize, StandardizeImage, ImagePermute\n",
    "\n",
    "from super_gradients.training import models\n",
    "from super_gradients.common.object_names import Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pprint\n",
    "import torch\n",
    "from torch import rand, randint\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, precision_recall_curve, average_precision_score, PrecisionRecallDisplay, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "pwd_notebook = os.path.abspath('') # path notebook\n",
    "root_path = os.path.dirname(os.path.dirname(pwd_notebook)) #path root project\n",
    "\n",
    "data_dir = os.path.join(root_path, 'data') #path data\n",
    "\n",
    "# train path\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "print(train_dir)\n",
    "# test path\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "print(test_dir)\n",
    "#valid path\n",
    "valid_dir = os.path.join(data_dir, 'valid')\n",
    "print(valid_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoints\n",
    "experiment_dir = os.path.join(root_path, 'checkpoints', 'class_mam')\n",
    "CHECKPOINT_DIR = os.path.join(experiment_dir, \"class_ckpt\")\n",
    "model_name = 'resnet18'\n",
    "trainer = Trainer(experiment_name=experiment_dir, ckpt_root_dir=CHECKPOINT_DIR)\n",
    "trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write transform for image\n",
    "data_transform = Compose([\n",
    "    # Resize the images to 64x64\n",
    "    # transforms.Resize(size=(64, 64)),\n",
    "    # Flip the images randomly on the horizontal\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # p = probability of flip, 0.5 = 50% chance\n",
    "    # Turn the image into a torch.Tensor\n",
    "    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transformed_images(image_paths, transform, n=3, seed=40):\n",
    "    \"\"\"Plots a series of random images from image_paths.\n",
    "\n",
    "    Will open n image paths from image_paths, transform them\n",
    "    with transform and plot them side by side.\n",
    "\n",
    "    Args:\n",
    "        image_paths (list): List of target image paths. \n",
    "        transform (PyTorch Transforms): Transforms to apply to images.\n",
    "        n (int, optional): Number of images to plot. Defaults to 3.\n",
    "        seed (int, optional): Random seed for the random generator. Defaults to 42.\n",
    "    \"\"\"\n",
    "    # random.seed(seed)\n",
    "    random_image_paths = random.sample(image_paths, k=n)\n",
    "    for image_path in random_image_paths:\n",
    "        with Image.open(image_path) as f:\n",
    "\n",
    "            fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "            # Normalize and display image in \"I\" mode\n",
    "            if f.mode == \"I\":\n",
    "                f_normalized = (np.array(f) - np.min(f)) / (np.max(f) - np.min(f)) * 255\n",
    "                ax[0].imshow(f_normalized)\n",
    "            else:\n",
    "                ax[0].imshow(f) \n",
    "                \n",
    "            ax[0].set_title(f\"Original \\nSize: {f.size} \\nMode:{f.mode}\")    \n",
    "            ax[0].axis(\"off\")\n",
    "\n",
    "            # Transform and plot image\n",
    "            # Note: permute() will change shape of image to suit matplotlib \n",
    "            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])\n",
    "            transformed_image = transform(f).permute(1, 2, 0) \n",
    "            ax[1].imshow(transformed_image) \n",
    "            ax[1].set_title(f\"Transformed \\nSize: {transformed_image.shape} \\nMode:{f.mode}\")\n",
    "            ax[1].axis(\"off\")\n",
    "\n",
    "            image_class = os.path.basename(os.path.dirname(image_path))\n",
    "\n",
    "            fig.suptitle(f\"Class: {image_class}\", fontsize=16)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "# random.seed(99) # <- try changing this and see what happens\n",
    "# 1. Get all image paths (* means \"any combination\")\n",
    "image_path_list = glob.glob(os.path.join(data_dir, '**', '*.png'), recursive=True)\n",
    "# 2. Get random image path\n",
    "random_image_path = random.choice(image_path_list)\n",
    "# 3. Get image class from path name (the image class is the name of the directory where the image is stored)\n",
    "image_class = os.path.basename(os.path.dirname(random_image_path))\n",
    "# 4. Open image\n",
    "img = Image.open(random_image_path)\n",
    "# 5. Print metadata\n",
    "print(f\"Random image path: {random_image_path}\")\n",
    "print(f\"Image class: {image_class}\")\n",
    "print(f\"Image height: {img.height}\") \n",
    "print(f\"Image width: {img.width}\")\n",
    "print(f\"Image mode: {img.mode}\")\n",
    "print(f\"Dataset Size: {len(image_path_list)}\")\n",
    "print(image_path_list)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show images\n",
    "plot_transformed_images(image_path_list, \n",
    "                        transform=data_transform, \n",
    "                        n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(root=train_dir, # target folder of images\n",
    "                                  transform=data_transform, # transforms to perform on data (images)\n",
    "                                  target_transform=None) # transforms to perform on labels (if necessary)\n",
    "\n",
    "valid_data = datasets.ImageFolder(root=valid_dir, \n",
    "                                 transform=data_transform,\n",
    "                                 target_transform=None)\n",
    "\n",
    "test_data = datasets.ImageFolder(root=test_dir, \n",
    "                                 transform=data_transform,\n",
    "                                 target_transform=None)\n",
    "\n",
    "print(f\"Train data:\\n{train_data}\\nValid data:\\n{valid_data}\\nTest data:\\n{test_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names as a list\n",
    "class_names = train_data.classes\n",
    "print(class_names)\n",
    "# Can also get class names as a dict\n",
    "class_dict = train_data.class_to_idx\n",
    "print(class_dict)\n",
    "# Check the lengths\n",
    "len(train_data), len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_data[5][0], train_data[5][1]\n",
    "print(f\"Image tensor:\\n{img}\")\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Image datatype: {img.dtype}\")\n",
    "print(f\"Image label: {label}\")\n",
    "print(f\"Label datatype: {type(label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange the order of dimensions\n",
    "img_permute = img.permute(1, 2, 0)\n",
    "\n",
    "# Print out different shapes (before and after permute)\n",
    "print(f\"Original shape: {img.shape} -> [color_channels, height, width]\")\n",
    "print(f\"Image permute shape: {img_permute.shape} -> [height, width, color_channels]\")\n",
    "\n",
    "# Plot the image\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.axis(\"off\")\n",
    "plt.title(class_names[label], fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_data, \n",
    "                              batch_size=16, # how many samples per batch?\n",
    "                              num_workers=10, # how many subprocesses to use for data loading? (higher = more)\n",
    "                              shuffle=True) # shuffle the data?\n",
    "\n",
    "valid_dataloader = DataLoader(dataset=valid_data, \n",
    "                             batch_size=16, \n",
    "                             num_workers=10, \n",
    "                             shuffle=True) # don't usually need to shuffle testing data\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data, \n",
    "                             batch_size=16, \n",
    "                             num_workers=20, \n",
    "                             shuffle=False) # don't usually need to shuffle testing data\n",
    "\n",
    "train_dataloader, valid_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = next(iter(train_dataloader))\n",
    "\n",
    "# Batch size will now be 1, try changing the batch_size parameter above and see what happens\n",
    "print(f\"Image shape: {img.shape} -> [batch_size, color_channels, height, width]\")\n",
    "print(f\"Label shape: {label.shape}\")\n",
    "print(f\"Train data:\\n{train_data}\\nValid data:\\n{valid_data}\\nTest data:\\n{test_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.get(model_name=Models.RESNET18, num_classes=6, pretrained_weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can see more recipes in super_gradients/recipes\n",
    "training_params =  training_hyperparams.get(\"training_hyperparams/imagenet_resnet50_train_params\")\n",
    "\n",
    "pprint.pprint(\"Training parameters\")\n",
    "pprint.pprint(training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params[\"max_epochs\"] = 5\n",
    "training_params[\"sg_logger_params\"][\"launch_tensorboard\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(root_path, 'logs', 'training_logs')\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(model=model,\n",
    "              training_params=training_params,\n",
    "              train_loader=train_dataloader,\n",
    "              valid_loader=valid_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an image from the test set (replace 'index' with the index of the image you want)\n",
    "index = 2  # Change this to the desired image index\n",
    "image, true_label = test_data[index]  # Get the image and its true label\n",
    "\n",
    "# Perform model inference on the image\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    image = image.unsqueeze(0)  # Add a batch dimension since the model expects batches\n",
    "    output = model(image.to(device))\n",
    "    _, predicted_label = torch.max(output, 1)  # Get the predicted label\n",
    "\n",
    "# Get the name of the predicted class from the index\n",
    "predicted_class = class_names[predicted_label.item()]\n",
    "true_class = class_names[true_label]\n",
    "\n",
    "# Show image along with predicted and true label\n",
    "plt.imshow(image.squeeze().permute(1, 2, 0))  # Show image (make sure dimensions are appropriate)\n",
    "plt.title(f\"Predicted: {predicted_class}\\nTrue: {true_class}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Evaluate the model on the test data set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate general metrics\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "report = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "# display = PrecisionRecallDisplay.from_estimator(preds, report, accuracy)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\\n\")\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(index=None):\n",
    "    if index is None:\n",
    "        index = random.randint(0, len(test_data)-1)\n",
    "    image, true_label = test_data[index]\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image_tensor = image.unsqueeze(0).to(device)\n",
    "        output = model(image_tensor)\n",
    "        _, predicted_label = torch.max(output, 1)\n",
    "        predicted_class = class_names[predicted_label.item()]\n",
    "        true_class = class_names[true_label]\n",
    "\n",
    "    plt.imshow(image.permute(1, 2, 0))  # Ensure dimensions are appropriate\n",
    "    plt.title(f\"Predicted: {predicted_class}\\nTrue: {true_class}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# View some random images with your predictions\n",
    "for _ in range(5):\n",
    "    visualize_predictions()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show graph Recall-Precision curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Recall-Precision Particular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain Probabilities of each Class\n",
    "\n",
    "y_true = []\n",
    "y_scores = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        probabilities = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_scores.extend(probabilities)\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_scores = np.array(y_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize tags in a one-vs-all format\n",
    "y_true_bin = label_binarize(y_true, classes=np.arange(len(class_names)))\n",
    "\n",
    "# Calculate precision and recall for each class\n",
    "for i in range(len(class_names)):\n",
    "    precision, recall, _ = precision_recall_curve(y_true_bin[:, i], y_scores[:, i])\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(recall, precision, marker='.')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve for {class_names[i]}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Precision-Recall Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize tags\n",
    "y_true_bin = label_binarize(y_true, classes=np.arange(len(class_names)))\n",
    "n_classes = len(class_names)\n",
    "\n",
    "# Calculate average precision and recall for each class\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "for i in range(n_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_true_bin[:, i], y_scores[:, i])\n",
    "    average_precision[i] = average_precision_score(y_true_bin[:, i], y_scores[:, i])\n",
    "\n",
    "# Colors for different classes\n",
    "colors = cycle(['blue', 'red', 'green', 'yellow', 'orange', 'purple'])\n",
    "\n",
    "# Draw Precision-Recall curves and iso-F1 curves\n",
    "plt.figure(figsize=(7, 8))\n",
    "f_scores = np.linspace(0.2, 0.8, num=6)\n",
    "for f_score in f_scores:\n",
    "    x = np.linspace(0.01, 1)\n",
    "    y = f_score * x / (2 * x - f_score)\n",
    "    # l, = plt.plot(x[y >= 0], y[y >= 0], color=\"gray\", alpha=0.2) # iso-F1 curves\n",
    "    plt.annotate(f\"f1={f_score:0.1f}\", xy=(0.9, y[45] + 0.02))\n",
    "\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(recall[i], precision[i], color=color, lw=2,\n",
    "             label=f'Precision-Recall curve of {class_names[i]} (AP = {average_precision[i]:0.2f})')\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Precision-Recall curve to multi-class\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC CURVE || FPR vs TNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize tags\n",
    "y_true_bin = label_binarize(y_true, classes=np.arange(len(class_names)))\n",
    "n_classes = len(class_names)\n",
    "\n",
    "# Calculate ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_scores[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Colors for different classes\n",
    "colors = cycle(['blue', 'red', 'green', 'yellow', 'orange', 'purple'])\n",
    "\n",
    "# Draw the ROC curve for each class\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'ROC curve of {class_names[i]} (area = {roc_auc[i]:0.2f})')\n",
    "\n",
    "# plt.plot([0, 1], [0, 1], 'k--', lw=2)  # Draw line for classifier\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (Fall out)')\n",
    "plt.ylabel('True Positive Rate (Sensivity)')\n",
    "plt.title('ROC Curve for Multi-Class FPR vs TPR')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC CURVE || Specificity vs Sensibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize tags\n",
    "y_true_bin = label_binarize(y_true, classes=np.arange(len(class_names)))\n",
    "n_classes = len(class_names)\n",
    "\n",
    "# Colors for different classes\n",
    "colors = cycle(['blue', 'red', 'green', 'yellow', 'orange', 'purple'])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Calculate ROC curve (TNR and TPR) and ROC area (AROC) for each class\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_scores[:, i])\n",
    "    tnr = 1 - fpr\n",
    "    roc_auc = auc(tnr, tpr)\n",
    "\n",
    "    plt.plot(tnr, tpr, color=color, lw=2, label=f'{class_names[i]} (AROC = {roc_auc:.2f})')\n",
    "\n",
    "plt.xlabel('True Negatives Rate (TNR - Specificity)')\n",
    "plt.ylabel('True Positive Rate (TPR - Sensibility)')\n",
    "plt.title('ROC Curve for Multi-Class Specificity vs Sensibility')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo-classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
