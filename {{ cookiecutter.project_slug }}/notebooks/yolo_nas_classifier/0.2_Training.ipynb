{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from super_gradients import Trainer\n",
    "from super_gradients.training import Trainer, training_hyperparams\n",
    "from super_gradients.training import models\n",
    "from super_gradients.common.object_names import Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pprint\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "pwd_notebook = os.path.abspath('') # path notebook\n",
    "root_path = os.path.dirname(os.path.dirname(pwd_notebook)) #path root project\n",
    "\n",
    "data_dir = os.path.join(root_path, 'data') #path data\n",
    "\n",
    "# train path\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "print(train_dir)\n",
    "# test path\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "print(test_dir)\n",
    "#valid path\n",
    "valid_dir = os.path.join(data_dir, 'valid')\n",
    "print(valid_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoints\n",
    "name_folder = 'clasificador' #Add Change the name of the folder\n",
    "experiment_name_value = 'distorsion_arquitectura' #Add Change the name of the experiment\n",
    "CHECKPOINT_DIR = os.path.join(root_path, 'checkpoints', name_folder) # path checkpoints\n",
    "\n",
    "# Create the checkpoint directory if it does not exist\n",
    "if not os.path.exists(CHECKPOINT_DIR):\n",
    "    os.makedirs(CHECKPOINT_DIR)\n",
    "\n",
    "\n",
    "pretrained_wegits_name = 'imagenet' #Add the name of the pretrained model\n",
    "trainer = Trainer(experiment_name=experiment_name_value, ckpt_root_dir=CHECKPOINT_DIR)\n",
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add parameters\n",
    "# number of classes\n",
    "n_classes = 4 #Add for your number classes\n",
    "\n",
    "#number epochs\n",
    "n_epochs = 30 #Add number checkpoints\n",
    "\n",
    "# learning rate\n",
    "lr_value = 0.1 #Add learning rate\n",
    "\n",
    "# size of image for resize\n",
    "size_image = (64, 64) #Add size image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write transform for image\n",
    "data_transform = Compose([\n",
    "    # Resize the images to 64x64\n",
    "    # transforms.Resize(size=size_image),\n",
    "    # Flip the images randomly on the horizontal\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # p = probability of flip, 0.5 = 50% chance\n",
    "    # Turn the image into a torch.Tensor\n",
    "    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning train, test and valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(root=train_dir, # target folder of images\n",
    "                                  transform=data_transform, # transforms to perform on data (images)\n",
    "                                  target_transform=None) # transforms to perform on labels (if necessary)\n",
    "\n",
    "valid_data = datasets.ImageFolder(root=valid_dir, \n",
    "                                 transform=data_transform,\n",
    "                                 target_transform=None)\n",
    "\n",
    "test_data = datasets.ImageFolder(root=test_dir, \n",
    "                                 transform=data_transform,\n",
    "                                 target_transform=None)\n",
    "\n",
    "print(f\"Train data:\\n{train_data}\\nValid data:\\n{valid_data}\\nTest data:\\n{test_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names as a list\n",
    "class_names = train_data.classes\n",
    "print(class_names)\n",
    "# Can also get class names as a dict\n",
    "class_dict = train_data.class_to_idx\n",
    "print(class_dict)\n",
    "# Check the lengths\n",
    "len(train_data), len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_data[5][0], train_data[5][1]\n",
    "print(f\"Image tensor:\\n{img}\")\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Image datatype: {img.dtype}\")\n",
    "print(f\"Image label: {label}\")\n",
    "print(f\"Label datatype: {type(label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange the order of dimensions\n",
    "img_permute = img.permute(1, 2, 0)\n",
    "\n",
    "# Print out different shapes (before and after permute)\n",
    "print(f\"Original shape: {img.shape} -> [color_channels, height, width]\")\n",
    "print(f\"Image permute shape: {img_permute.shape} -> [height, width, color_channels]\")\n",
    "\n",
    "# Plot the image\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.axis(\"off\")\n",
    "plt.title(class_names[label], fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_data, \n",
    "                              batch_size=16, # how many samples per batch?\n",
    "                              num_workers=10, # how many subprocesses to use for data loading? (higher = more)\n",
    "                              shuffle=True) # shuffle the data?\n",
    "\n",
    "valid_dataloader = DataLoader(dataset=valid_data, \n",
    "                             batch_size=16, \n",
    "                             num_workers=10, \n",
    "                             shuffle=True) # don't usually need to shuffle testing data\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data, \n",
    "                             batch_size=16, \n",
    "                             num_workers=20, \n",
    "                             shuffle=False) # don't usually need to shuffle testing data\n",
    "\n",
    "train_dataloader, valid_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = next(iter(train_dataloader))\n",
    "\n",
    "# Batch size will now be 1, try changing the batch_size parameter above and see what happens\n",
    "print(f\"Image shape: {img.shape} -> [batch_size, color_channels, height, width]\")\n",
    "print(f\"Label shape: {label.shape}\")\n",
    "print(f\"Train data:\\n{train_data}\\nValid data:\\n{valid_data}\\nTest data:\\n{test_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.get(\n",
    "    model_name=Models.RESNET50, #Add the name of the model\n",
    "    num_classes=n_classes, \n",
    "    pretrained_weights=pretrained_wegits_name)\n",
    "print(model.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can see more recipes in super_gradients/recipes\n",
    "training_params =  training_hyperparams.get(\"training_hyperparams/imagenet_resnet50_train_params\")\n",
    "\n",
    "pprint.pprint(\"Training parameters\")\n",
    "pprint.pprint(training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the parameters you want\n",
    "training_params[\"max_epochs\"] = n_epochs\n",
    "training_params[\"launch_tensorboard\"] = True\n",
    "training_params[\"sg_logger_params\"][\"launch_tensorboard\"] = True\n",
    "training_params[\"train_metrics_list\"] = [\"Accuracy\"]\n",
    "training_params[\"valid_metrics_list\"] = [\"Accuracy\"]\n",
    "training_params[\"initial_lr\"] = lr_value\n",
    "\n",
    "pprint.pprint(\"Training parameters Current\")\n",
    "pprint.pprint(training_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for find the last checkpoint\n",
    "\n",
    "def find_last_run_dir(base_dir):\n",
    "    # Builds the search pattern to identify folders starting with \"RUN_\"\n",
    "    search_pattern = os.path.join(base_dir, \"RUN_*\")\n",
    "    # Finds all folders that match the pattern\n",
    "    list_run_dirs = glob.glob(search_pattern)\n",
    "    # If no directories are found, it returns None\n",
    "    if not list_run_dirs:\n",
    "        return None\n",
    "    \n",
    "    # Sort directories by date and time from most recent to oldest\n",
    "    latest_list_run_dirs = sorted(list_run_dirs, key=os.path.getmtime, reverse=True)[0]\n",
    "    return latest_list_run_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show logs of model\n",
    "log_dir = os.path.join(CHECKPOINT_DIR, experiment_name_value)\n",
    "latest_log_dir = find_last_run_dir(log_dir)\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir='{latest_log_dir}'\n",
    "%reload_ext tensorboard\n",
    "\n",
    "print(f\"Last log dir: {latest_log_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(model=model,\n",
    "              training_params=training_params,\n",
    "              train_loader=train_dataloader,\n",
    "              valid_loader=valid_dataloader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo-classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
